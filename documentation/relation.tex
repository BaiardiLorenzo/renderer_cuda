% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}
\usepackage[italian]{babel}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{float}
\usepackage{csvsimple}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{mdwtab}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}
\graphicspath{{../results/}}

% Document
\title{Problemi di Render: Parallel Programming for Machine Learning}
\author{Lorenzo Baiardi, Thomas Del Moro}
\date{10 12 2023}

\begin{document}

    \maketitle
    \clearpage

    \section{Introduzione}\label{sec:introduzione}
    In questo documento, esamineremo attentamente l'efficacia dell'applicazione di diversi metodi di parallelizzazione
    su problematiche comuni, analizzando in dettaglio i tempi di esecuzione associati.
    Concentreremo la nostra valutazione sul metodo del compositing tra piani, utilizzando la libreria grafica OpenCV
    come strumento principale per condurre le nostre analisi.

    \section{Analisi del problema}\label{sec:analisi-del-problema}
    Ciascun piano è caratterizzato da quattro canali di colore (RGBA), e su ogni piano saranno disegnati casualmente n cerchi.
    Nel processo di compositing dei piani, sarà implementato un effetto di trasparenza, il quale dipenderà dalla
    posizione relativa di ciascun piano all'interno della sommatoria.
    Questa strategia mira a creare un effetto visivo di profondità.
    L'immagine risultante sarà salvata nel formato PNG e si focalizzerà principalmente sul piano posizionato più in alto,
    evidenziando così principalmente i cerchi associati a esso.

    \begin{figure}[h!]
        \begin{minipage}{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{img/seq/10000}
            \caption{Sequenziale}
        \end{minipage}%
        \hfill
        \begin{minipage}{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{img/par/10000}
            \caption{OMP}
        \end{minipage}%
        \hfill
        \begin{minipage}{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{img/cuda/10000}
            \caption{CUDA}
        \end{minipage}
        \caption{Immagini di esempio}\label{fig:example-images}
    \end{figure}

    \section{Metodi di parallelizzazione}\label{sec:metodi-di-parallelizazzione}

    Per parallelizzare la problematica, abbiamo optato per l'adozione di due approcci distinti.
    Nel primo scenario, abbiamo impiegato la libreria OPENMP, esplorando le variazioni nel numero di thread.
    Nel secondo caso, abbiamo invece sfruttato il linguaggio di programmazione CUDA per eseguire calcoli in parallelo sulla scheda grafica.
    \lstinputlisting[language=c++, firstline=39, lastline=63,label={lst:sequential-code}]{../src/renderer.cu}

    \subsection{OPENMP}\label{subsec:openmp}
    L'approccio fondamentale consiste nell'assegnare a ciascun thread la responsabilità di gestire la sommatoria di un
    singolo pixel per ogni matrice.
    Questo permette di mantenere l'ordine dei piani, mentre allo stesso tempo incrementa la velocità di rendering complessiva.
    Ogni thread, di conseguenza, elaborerà il pixel risultante e procederà successivamente al calcolo del pixel successivo
    una volta completata l'operazione corrente.
    \lstinputlisting[language=c++, firstline=66, lastline=91,label={lst:parallel-code}]{../src/renderer.cu}

    \subsection{CUDA}\label{subsec:cuda}
    Attraverso un attento calcolo dei parametri di grid e block, miriamo a ottimizzare l'allocazione delle risorse sulla scheda grafica.
    Definendo una suddivisione efficiente del lavoro tra i thread e i blocchi, intendiamo massimizzare la parallelizzazione,
    sfruttando appieno la capacità computazionale offerta dalla scheda grafica.
    Questo approccio mirato a una gestione ottimale delle risorse è essenziale per garantire prestazioni elevate nel contesto
    del calcolo parallelo mediante CUDA\@.
    \lstinputlisting[language=c++, firstline=143, lastline=163,label={lst:cuda-code}]{../src/renderer.cu}

    \section{Caratteristiche della macchina}\label{sec:caratteristiche-della-macchina}
    La macchina utilizzata per effettuare i test è dotata di:
    \begin{itemize}
        \item Processore Intel Core i5-8600K 3.60 GHz (6 core)
        \item 16 GB di RAM
        \item Scheda grafica NVIDIA GeForce GTX 1050 Ti 4 GB
        \item Sistema operativo Windows 11
    \end{itemize}

    \section{Tests}\label{sec:tests}
    \input{tests}

    \section{Conclusioni}\label{sec:conclusioni}
    In sintesi, come evidenziato dai test condotti, la parallelizzazione mediante CUDA si distingue per il notevole
    incremento di speedup riscontrato nelle diverse prove.
    Questo risultato è principalmente attribuibile alla progettazione della scheda grafica, ottimizzata per eseguire
    operazioni in parallelo e sfruttare appieno la sua potenza computazionale.

    Inoltre, l'analisi dei test dimostra che l'incremento di velocità è più significativo all'aumentare del numero di piani.
    Ciò è dovuto alla capacità della scheda grafica di massimizzare la sua potenza di calcolo in relazione al numero crescente di piani.

    È interessante notare che la versione parallela di OpenMP registra un aumento di velocità notevole rispetto alla versione sequenziale,
    soprattutto con l'incremento del numero di thread disponibili sulla macchina.

\end{document}