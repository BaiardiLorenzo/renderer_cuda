% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}
\usepackage[italian]{babel}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{float}
\usepackage{csvsimple}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{mdwtab}
\usepackage{array}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\scriptsize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

% Document
\title{Problemi di Render: Parallel Programming for Machine Learning}
\author{Lorenzo Baiardi, Thomas Del Moro}
\date{10 12 2023}

\begin{document}

    \maketitle

    \section{Introduzione}\label{sec:introduzione}
    In questo documento, analizzeremo l'efficacia dell'applicazione di diversi metodi di parallelizzazione
    sul problema di compositing tra piani, osservando in dettaglio i tempi di esecuzione associati.
    Il task consiste nel costruire un Renderer di cerchi di colore diverso e parzialmente trasparenti,
    attraverso i quali si possano quindi intravedere i cerchi dei piani sottostanti.

    \section{Analisi del problema}\label{sec:analisi-del-problema}
    Introduciamo alcune definizioni che ci torneranno utili:
    \begin{itemize}
        \item $n$ : numero di cerchi per ogni piano
        \item $N$ : numero di piani da sovrapporre
        \item $D$ : dimensione 2D di ogni piano
    \end{itemize}
    Ciascun piano è caratterizzato da quattro canali di colore (RGBA, ovvero RGB con trasparenza),
    in modo da creare un effetto visivo i trasparenza.
    Su ogni piano vengono disegnati $n$ cerchi di colore diverso, dopodiché tali immagini vengono sovrapposte dalla
    prima all'ultima.
    In questa fase sarà utilizzato il canale di trasparenza e sarà importante l'ordine con cui verrà eseguito il compositing.
    L'immagine risultante sarà un insieme dei cerchi dell'ultimo piano, attraverso i quali si intravederanno quelli
    dei piani sottostanti.\\

    Eseguiremo il task sia in maniera sequenziale che in modo parallelo, utilizzando diverse tecniche e linguaggi di parallelizzazione.
    In Figura~\ref{fig:example-images} è mostrato un esempio del risultato ottenuto con $N=3000$ e $n=50$ usando i
    diversi metodi di parallelizzazione testati.

    \begin{figure}[h!]
        \begin{subfigure}{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../results/img/seq/3000}
            \caption{Sequenziale}
        \end{subfigure}%
        \hfill
        \begin{subfigure}{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../results/img/par/3000}
            \caption{OMP}
        \end{subfigure}%
        \hfill
        \begin{subfigure}{0.32\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../results/img/cuda/3000}
            \caption{CUDA}
        \end{subfigure}
        \caption{Immagini di esempio}
        \label{fig:example-images}
    \end{figure}

    \section{Implementazione}\label{sec:implementazione}
    Abbiamo realizzato il progetto in linguaggio C++, facendo uso della libreria OpenCV per la realizzazione delle immagini.
    Innanzitutto vengono generati casualmente i cerchi e inseriti nei rispettivi piani.
    Tutti tali dati vengono salvati in un array di matrici di OpenCV che poi saranno processati.
    \lstinputlisting[language=c++, firstline=3, lastline=32,label={lst:sequential-gen}]{../src/renderer.cu}
    Una volta generati i piani separatamente, questi vengono sovrapposti sequenzialmente l'uno con l'altro,
    sommando a ogni iterazione il piano corrente al risultato dei piani precedenti.
    \lstinputlisting[language=c++, firstline=67, lastline=91,label={lst:sequential-code}]{../src/renderer.cu}
    Vediamo dunque in modo più specifico le tecniche di parallelizzazione utilizzate.

    \section{Parallelizzazione}\label{sec:parallelizzazione}
    Per parallelizzare la problematica, abbiamo optato per l'adozione di due approcci distinti.
    Nel primo scenario, abbiamo impiegato la libreria OpenMP, che permette di eseguire più thread contemporaneamente
    sulla CPU della nostra macchina.
    Nel secondo caso, abbiamo invece sfruttato il linguaggio di programmazione CUDA per eseguire calcoli in parallelo
    sulla GPU a disposizione.

    \subsection{OpenMP}\label{subsec:openmp}
    OpenMP si tratta di un API per la programmazione parallela su sistemi a memoria condivisa.
    È composto da un insieme di direttive di compilazione, routine di librerie e variabili d'ambiente che consentono di
    sviluppare applicazioni di calcolo parallele sfruttando i diversi core delle CPU moderne.\\
    \subsubsection{Generazione dei cerchi}
    Poiché la generazione dei cerchi impiega tempi molto lunghi, abbiamo prima di tutto utilizzato OpenMP per
    velocizzare questo processo.
    \lstinputlisting[language=c++, firstline=34, lastline=64, label={lst:parallel-gen}]{../src/renderer.cu}
    Come si può notare nello codice sopra, alla riga 10 è stata aggiunta una direttiva per la definizione di un loop
    parallelo, eseguito quindi da più thread contemporaneamente.
    Poiché l'ordine in cui i cerchi vengono generati non è importante, si tratta di un problema imbarazzantemente parallelizzabile.
    Allo stesso modo, alla riga 24 è stato definito un secondo loop parallelo per suddividere l'assegnazione tra cerchi e piani tra thread diversi.
    \subsubsection{Rendering}
    Passiamo adesso ad analizzare il task principale, ovvero quello del compositing dei piani.
    Dopo aver esplorato varie possibilità, l'approccio migliore è risultato quello di assegnare a ciascun thread la
    sommatoria su tutti i piani di un singolo pixel per ogni matrice.
    Questo metodo permette di mantenere l'ordine dei piani, poiché per ogni pixel la sommatoria viene eseguita
    sequenzialmente, ma allo stesso tempo incrementa la velocità di rendering complessiva dato che pixel diversi sono
    assegnati a thread diversi ed elaborati contemporaneamente.
    Un thread, dunque, a ogni iterazione utilizza il pixel risultante dai piani precedenti e somma a questo il pixel
    del piano corrente.
    Una volta completata l'operazione per tutti i piani il thread viene assegnato a un nuovo pixel finché la matrice 2D non si è esaurita.
    \lstinputlisting[language=c++, firstline=94, lastline=119, label={lst:parallel-code}]{../src/renderer.cu}
    Come si può notare dallo snippet di codice sopra, alla riga 8 è stata inserita una direttiva OpenMP per definire un loop parallelo.
    La clausola $collapse(2)$ permette di parallelizzare sui primi due cicli più esterni, ovvero sia sulle righe che sulle colonne della matrice.\\

    \subsection{CUDA}\label{subsec:cuda}
    CUDA è un architettura hardware per l'elaborazione parallela sviluppata da NVIDIA, che permette di sviluppare codice eseguibile su GPU.
    La GPU permette di fare affidamento su un gran numero di core a differenza del singolo processore e ciò permette di
    realizzare applicazioni parallele estremamente veloci.\\

    Anche in questo caso abbiamo valutato diversi approcci, di cui alcuni sono risultati più efficienti di altri.
    In particolare, il metodo che sembra ottenere il miglior speedup è mostrato nel seguente snippet di codice, in cui
    si affida a ogni thread la sommatoria su tutti i piani di un solo pixel, analogamente a quanto fatto con OpenMP.
    Costruiamo blocchi 8x8, 16x16 0 32x32 in modo da non superare i limite della nostra GPU di 1024 thread per blocco ma
    allo stesso tempo da avere sempre un numero di thread multiplo di 32 per ottenere un vantaggio nell'istanziamento degli warp.
    Il numero di blocchi varia quindi in base alla dimensione di ogni blocco, in modo da assegnare ciascun thread un pixel della matrice.\\
    \lstinputlisting[language=c++, firstline=127, lastline=129,label={lst:cuda-grid}]{../src/renderer.cu}
    \lstinputlisting[language=c++, firstline=171, lastline=191,label={lst:cuda-code}]{../src/renderer.cu}
    Notiamo che in questo modo la sommatoria sui piani viene eseguita in modo sequenziale da un singolo thread,
    dunque l'immagine risultate non subisce trasformazioni errate.


    \section{Caratteristiche della macchina}\label{sec:caratteristiche-della-macchina}
    Per condurre i test con OpenMP e CUDA, abbiamo utilizzato due macchine diverse:\\
    La macchina utilizzata per effettuare i test con OpenMP è dotata di:
    \begin{itemize}
        \item \textbf{CPU}: Intel Core i7-1360P (4 P-Core, 8 E-Core, 12 Cores, 16 Threads)
        \item \textbf{RAM}: 16 GB
        \item \textbf{Sistema Operativo}: Windows 11 Home
        \item \textbf{Librerie}: OpenCV 4.6.0
    \end{itemize}

    La macchina utilizzata per effettuare i test con CUDA è dotata di:
    \begin{itemize}
        \item \textbf{CPU}: Intel Core i5-8600K 3.60 GHz (6 core)
        \item \textbf{RAM}: 16 GB
        \item \textbf{GPU} NVIDIA GeForce GTX 1050 Ti 4 GB
        \item \textbf{Sistema Operativo}: Windows 11 PRO
        \item \textbf{Librerie}: OpenCV 4.6.0, CUDA 11.8
    \end{itemize}

    \section{Esperimenti e Risultati}\label{sec:tests}
    \input{tests}

    \section{Conclusioni}\label{sec:conclusioni}
    In sintesi, come evidenziato dai test condotti, la parallelizzazione permette in ogni caso di gestire il problema
    di compositing dei piani in modo molto più veloce rispetto alla semplice computazione sequenziale.
    In particolare, l'approccio CUDA si è rivelato molto efficace per questo problema, permettendo di ottenere uno
    speedup molto significativo.
    OpenMP, pur non raggiungendo lo stesso livello di efficienza, ha comunque permesso di ottenere un miglioramento
    importante rispetto alla versione sequenziale.
    Entrambi questi metodi diventano particolarmente utili quando la quantità di dati da processare aumenta molto,
    rendendo quasi impraticabile la soluzione sequenziale.

    \clearpage

    \appendix
    \input{appendixA}

\end{document}